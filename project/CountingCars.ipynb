{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CountingCars.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqBc8GQattRE"
      },
      "outputs": [],
      "source": [
        "from models import *\n",
        "from utils import *\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import os, sys, time, datetime, random\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_path='content/config/yolov3.cfg'\n",
        "weights_path='content/config/yolov3.weights'\n",
        "class_path='content/config/coco.names'\n",
        "img_size=416\n",
        "conf_thres=0.8\n",
        "nms_thres=0.4\n",
        "\n",
        "# Load model and weights\n",
        "model = Darknet(config_path, img_size=img_size)\n",
        "model.load_weights(weights_path)\n",
        "# model.cuda()\n",
        "model.eval()\n",
        "classes = utils.load_classes(class_path)\n",
        "Tensor = torch.FloatTensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B26cmqm3uKrU",
        "outputId": "9fd2ea5b-4d22-4fa4-993c-be4e48a77c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_image(img):\n",
        "    # scale and pad image\n",
        "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
        "    imw = round(img.size[0] * ratio)\n",
        "    imh = round(img.size[1] * ratio)\n",
        "    img_transforms = transforms.Compose([ transforms.Resize((imh, imw)),\n",
        "         transforms.Pad((max(int((imh-imw)/2),0), max(int((imw-imh)/2),0), max(int((imh-imw)/2),0), max(int((imw-imh)/2),0)),\n",
        "                        (128,128,128)),\n",
        "         transforms.ToTensor(),\n",
        "         ])\n",
        "    # convert image to Tensor\n",
        "    image_tensor = img_transforms(img).float()\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "    input_img = Variable(image_tensor.type(Tensor))\n",
        "    # run inference on the model and get detections\n",
        "    with torch.no_grad():\n",
        "        detections = model(input_img)\n",
        "        detections = utils.non_max_suppression(detections, 80, conf_thres, nms_thres)\n",
        "    return detections[0]"
      ],
      "metadata": {
        "id": "EqXO-NzfuKuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_contour_width=40  #40\n",
        "min_contour_height=40  #40\n",
        "offset=10       #10\n",
        "line_height=550 #550\n",
        "matches =[]\n",
        "cars=0\n",
        "def get_centroid(x, y, w, h):\n",
        "    x1 = int(w / 2)\n",
        "    y1 = int(h / 2)\n",
        "\n",
        "    cx = x + x1\n",
        "    cy = y + y1\n",
        "    return cx,cy\n",
        "    #return (cx, cy)\n",
        "        \n",
        "#cap = cv2.VideoCapture(0)\n",
        "cap = cv2.VideoCapture('/content/Traffic.mp4')\n",
        "\n",
        "\n",
        "cap.set(3,1920)\n",
        "cap.set(4,1080)\n",
        "\n",
        "if cap.isOpened():\n",
        "    ret,frame1 = cap.read()\n",
        "else:\n",
        "    ret = False\n",
        "ret,frame1 = cap.read()\n",
        "ret,frame2 = cap.read()\n",
        "    \n",
        "while ret:\n",
        "    d = cv2.absdiff(frame1,frame2)\n",
        "    grey = cv2.cvtColor(d,cv2.COLOR_BGR2GRAY)\n",
        "    #blur = cv2.GaussianBlur(grey,(5,5),0)\n",
        "    blur = cv2.GaussianBlur(grey,(5,5),0)\n",
        "    #ret , th = cv2.threshold(blur,20,255,cv2.THRESH_BINARY)\n",
        "    ret , th = cv2.threshold(blur,20,255,cv2.THRESH_BINARY)\n",
        "    dilated = cv2.dilate(th,np.ones((3,3)))\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
        "\n",
        "        # Fill any small holes\n",
        "    closing = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel) \n",
        "    contours,h = cv2.findContours(closing,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for(i,c) in enumerate(contours):\n",
        "        (x,y,w,h) = cv2.boundingRect(c)\n",
        "        contour_valid = (w >= min_contour_width) and (\n",
        "            h >= min_contour_height)\n",
        "\n",
        "        if not contour_valid:\n",
        "            continue\n",
        "        cv2.rectangle(frame1,(x-10,y-10),(x+w+10,y+h+10),(255,0,0),2)\n",
        "        \n",
        "        cv2.line(frame1, (0, line_height), (1200, line_height), (0,255,0), 2)\n",
        "        centroid = get_centroid(x, y, w, h)\n",
        "        matches.append(centroid)\n",
        "        cv2.circle(frame1,centroid, 5, (0,255,0), -1)\n",
        "        cx,cy= get_centroid(x, y, w, h)\n",
        "        for (x,y) in matches:\n",
        "            if y<(line_height+offset) and y>(line_height-offset):\n",
        "                matches.remove((x,y))\n",
        "                \n",
        "    cv2.putText(frame1, \"Total Cars Detected: \" + str(cars), (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
        "                    (0, 170, 0), 2)\n",
        "\n",
        "    cv2.putText(frame1, \"RCNN Detection: \", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
        "                    (255, 170, 0), 2)\n",
        "    \n",
        "    \n",
        "    \n",
        "    #cv2.drawContours(frame1,contours,-1,(0,0,255),2)\n",
        "\n",
        "\n",
        "    cv2.imshow(\"Original\" , frame1)\n",
        "    # cv2.imshow(\"Difference\" , th)\n",
        "    if cv2.waitKey(1) == 27:\n",
        "        break\n",
        "    frame1 = frame2\n",
        "    ret , frame2 = cap.read()\n",
        "#print(matches)    \n",
        "cv2.destroyAllWindows()\n",
        "cap.release()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "HHYP61fNuKxl",
        "outputId": "e6cb9d19-9c21-4291-83fc-aa1c4c9f902d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-89ad1b769e38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m   \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jWL-wtIPuK0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cf2lnyvJuK3I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}